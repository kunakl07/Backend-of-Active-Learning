{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sir_Val's_method_color.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6XmAmzmR4Gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "460ef800-bfe6-44c2-adcf-264f1f52b3b0"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import InceptionResNetV2\n",
        "import sys \n",
        "import numpy\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers, regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, Activation, Input\n",
        "from keras import callbacks, regularizers\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.engine import  Model\n",
        "from keras.layers import Conv2D, GlobalAveragePooling2D\n",
        "from sklearn import metrics\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWVBax3CZflR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9906ac28-55d7-49cd-badc-edf61ca90f2e"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/No_preprocess_train(1).zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(file_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/No_preprocess_train(1).zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpATYjlhZrf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7ca9098-0b74-45e9-e372-b5c7f2154078"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/No_preprocess_test(1).zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(file_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/No_preprocess_test(1).zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqy8dI7QaCk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55a33bde-b7ed-4b2b-d3d8-745a0b406675"
      },
      "source": [
        "import cv2\n",
        "k=cv2.imread(\"/content/content/Round2_OS_07_05/test/calls/calls_pod31.png\")\n",
        "k.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(288, 432, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO-rgZihZaPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bab3aa26-e2c7-450a-d78f-21f2dfa49d31"
      },
      "source": [
        "train_data_path = '/content/content/Round2_OS_07_05/train/'\n",
        "test_data_path = '/content/test/'\n",
        "img_width, img_height = 288, 432\n",
        "nb_test_samples = sum(len(files) for _, _, files in os.walk(test_data_path))\n",
        "epochs = 100\n",
        "batch_size = 157\n",
        "print(nb_test_samples)\n",
        "nb_train_samples = sum(len(files) for _, _, files in os.walk(train_data_path))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8iYrNwtZ5lA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "3f13cebf-e868-4109-a3cd-65957058a047"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5, 5), padding = 'same', strides=3, input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), strides=3, padding = 'same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (5, 5), strides=3, padding = 'same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=3e-5),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 96, 144, 64)       4864      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 96, 144, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 96, 144, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 48, 64)        102464    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 11, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 11, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 22528)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               5767424   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 6,079,937\n",
            "Trainable params: 6,079,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZ0tpUPaOp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e298377-7541-44e3-f491-bbb6c2001c29"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_batchsize = 157\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=train_batchsize,\n",
        "    class_mode='binary',\n",
        "shuffle=True)\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=epochs\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1570 images belonging to 2 classes.\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 9s 909ms/step - loss: 0.6962 - accuracy: 0.5121\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 9s 871ms/step - loss: 0.6978 - accuracy: 0.4994\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 9s 871ms/step - loss: 0.6911 - accuracy: 0.5338\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 9s 880ms/step - loss: 0.6937 - accuracy: 0.5223\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 9s 877ms/step - loss: 0.6944 - accuracy: 0.5299\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 9s 880ms/step - loss: 0.6917 - accuracy: 0.5223\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 9s 886ms/step - loss: 0.6889 - accuracy: 0.5306\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 9s 875ms/step - loss: 0.6858 - accuracy: 0.5675\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 9s 873ms/step - loss: 0.6838 - accuracy: 0.5586\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 9s 890ms/step - loss: 0.6754 - accuracy: 0.5732\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 9s 872ms/step - loss: 0.6728 - accuracy: 0.5822\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 9s 869ms/step - loss: 0.6642 - accuracy: 0.5981\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 9s 863ms/step - loss: 0.6523 - accuracy: 0.6146\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 9s 884ms/step - loss: 0.6436 - accuracy: 0.6172\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.6445 - accuracy: 0.6083\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 9s 877ms/step - loss: 0.6440 - accuracy: 0.6089\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 9s 878ms/step - loss: 0.6378 - accuracy: 0.6248\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 9s 873ms/step - loss: 0.6361 - accuracy: 0.6299\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 9s 880ms/step - loss: 0.6275 - accuracy: 0.6293\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 9s 883ms/step - loss: 0.6304 - accuracy: 0.6420\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 9s 874ms/step - loss: 0.6254 - accuracy: 0.6338\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 9s 865ms/step - loss: 0.6263 - accuracy: 0.6503\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 9s 870ms/step - loss: 0.6277 - accuracy: 0.6503\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 9s 877ms/step - loss: 0.6246 - accuracy: 0.6420\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 9s 873ms/step - loss: 0.6274 - accuracy: 0.6478\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 9s 868ms/step - loss: 0.6225 - accuracy: 0.6465\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 9s 865ms/step - loss: 0.6231 - accuracy: 0.6465\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 9s 868ms/step - loss: 0.6261 - accuracy: 0.6490\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 9s 862ms/step - loss: 0.6301 - accuracy: 0.6465\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.6254 - accuracy: 0.6401\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.6190 - accuracy: 0.6573\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.6246 - accuracy: 0.6465\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.6278 - accuracy: 0.6420\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.6235 - accuracy: 0.6363\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.6264 - accuracy: 0.6382\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.6223 - accuracy: 0.6535\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6248 - accuracy: 0.6490\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.6189 - accuracy: 0.6446\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6187 - accuracy: 0.6573\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.6187 - accuracy: 0.6580\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.6194 - accuracy: 0.6567\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 8s 839ms/step - loss: 0.6213 - accuracy: 0.6510\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.6200 - accuracy: 0.6586\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.6141 - accuracy: 0.6471\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.6208 - accuracy: 0.6650\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 9s 852ms/step - loss: 0.6214 - accuracy: 0.6478\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.6130 - accuracy: 0.6599\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.6148 - accuracy: 0.6529\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.6165 - accuracy: 0.6580\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6166 - accuracy: 0.6522\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.6107 - accuracy: 0.6682\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.6137 - accuracy: 0.6624\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.6127 - accuracy: 0.6624\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.6134 - accuracy: 0.6561\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.6140 - accuracy: 0.6497\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6094 - accuracy: 0.6624\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.6140 - accuracy: 0.6650\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.6151 - accuracy: 0.6567\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.6095 - accuracy: 0.6631\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.6114 - accuracy: 0.6726\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.6086 - accuracy: 0.6752\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.6076 - accuracy: 0.6650\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.6134 - accuracy: 0.6618\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.6104 - accuracy: 0.6573\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6094 - accuracy: 0.6637\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.6031 - accuracy: 0.6720\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.6064 - accuracy: 0.6713\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.6039 - accuracy: 0.6624\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.6029 - accuracy: 0.6688\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.6030 - accuracy: 0.6694\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.6045 - accuracy: 0.6694\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.6024 - accuracy: 0.6720\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.6033 - accuracy: 0.6643\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.6019 - accuracy: 0.6732\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.5976 - accuracy: 0.6796\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.5997 - accuracy: 0.6752\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.5968 - accuracy: 0.6809\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.5997 - accuracy: 0.6790\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.5920 - accuracy: 0.6809\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.5911 - accuracy: 0.6873\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.5959 - accuracy: 0.6809\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.5906 - accuracy: 0.6904\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.5956 - accuracy: 0.6771\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.5920 - accuracy: 0.6745\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.5858 - accuracy: 0.6841\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.5917 - accuracy: 0.6739\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.5928 - accuracy: 0.6777\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.5865 - accuracy: 0.6917\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.5872 - accuracy: 0.6943\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.5836 - accuracy: 0.6828\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.5828 - accuracy: 0.6930\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.5815 - accuracy: 0.6834\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.5767 - accuracy: 0.6892\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.5751 - accuracy: 0.6994\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.5782 - accuracy: 0.6904\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.5746 - accuracy: 0.6975\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.5703 - accuracy: 0.6987\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.5672 - accuracy: 0.7032\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.5665 - accuracy: 0.7083\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.5659 - accuracy: 0.7115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2pUD5mDaUc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "413d3e01-c4ca-4df3-9b56-1a091d9452b1"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=100\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.5652 - accuracy: 0.6975\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.5684 - accuracy: 0.6981\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 8s 847ms/step - loss: 0.5645 - accuracy: 0.6975\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.5642 - accuracy: 0.7089\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 8s 837ms/step - loss: 0.5606 - accuracy: 0.6975\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.5672 - accuracy: 0.6962\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 8s 834ms/step - loss: 0.5596 - accuracy: 0.6936\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.5537 - accuracy: 0.7146\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.5527 - accuracy: 0.7134\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.5466 - accuracy: 0.7146\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.5515 - accuracy: 0.7146\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.5421 - accuracy: 0.7178\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.5406 - accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.5375 - accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.5388 - accuracy: 0.7299\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.5350 - accuracy: 0.7102\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.5339 - accuracy: 0.7178\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.5327 - accuracy: 0.7204\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.5337 - accuracy: 0.7268\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.5366 - accuracy: 0.7293\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.5230 - accuracy: 0.7401\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.5269 - accuracy: 0.7293\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.5237 - accuracy: 0.7140\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.5259 - accuracy: 0.7280\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.5205 - accuracy: 0.7395\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.5215 - accuracy: 0.7287\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.5150 - accuracy: 0.7318\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.5026 - accuracy: 0.7357\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.5010 - accuracy: 0.7427\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.5189 - accuracy: 0.7338\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.5111 - accuracy: 0.7376\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.5063 - accuracy: 0.7452\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.5025 - accuracy: 0.7363\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.5055 - accuracy: 0.7344\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4909 - accuracy: 0.7586\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.4915 - accuracy: 0.7554\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4968 - accuracy: 0.7414\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.5062 - accuracy: 0.7490\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.5018 - accuracy: 0.7389\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.4960 - accuracy: 0.7420\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4941 - accuracy: 0.7471\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4965 - accuracy: 0.7408\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4971 - accuracy: 0.7471\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.4887 - accuracy: 0.7446\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4947 - accuracy: 0.7433\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.4876 - accuracy: 0.7529\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4933 - accuracy: 0.7516\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4815 - accuracy: 0.7662\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.4845 - accuracy: 0.7586\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4774 - accuracy: 0.7548\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4720 - accuracy: 0.7618\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.4770 - accuracy: 0.7541\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4746 - accuracy: 0.7586\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4819 - accuracy: 0.7554\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4736 - accuracy: 0.7624\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4790 - accuracy: 0.7650\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4732 - accuracy: 0.7618\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4737 - accuracy: 0.7592\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4685 - accuracy: 0.7618\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4638 - accuracy: 0.7713\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4695 - accuracy: 0.7726\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.4649 - accuracy: 0.7726\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4736 - accuracy: 0.7541\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4735 - accuracy: 0.7771\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4788 - accuracy: 0.7573\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4744 - accuracy: 0.7624\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4668 - accuracy: 0.7694\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4623 - accuracy: 0.7771\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.4676 - accuracy: 0.7771\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.4560 - accuracy: 0.7777\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4662 - accuracy: 0.7707\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4600 - accuracy: 0.7726\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4543 - accuracy: 0.7713\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4612 - accuracy: 0.7669\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.4549 - accuracy: 0.7822\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4441 - accuracy: 0.7847\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4493 - accuracy: 0.7873\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.4507 - accuracy: 0.7828\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.4444 - accuracy: 0.7815\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4549 - accuracy: 0.7713\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4493 - accuracy: 0.7701\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4516 - accuracy: 0.7790\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4489 - accuracy: 0.7764\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4564 - accuracy: 0.7726\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4520 - accuracy: 0.7656\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4506 - accuracy: 0.7739\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4582 - accuracy: 0.7771\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.4474 - accuracy: 0.7885\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4427 - accuracy: 0.7783\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.4515 - accuracy: 0.7885\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4502 - accuracy: 0.7790\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4471 - accuracy: 0.7841\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4382 - accuracy: 0.7968\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.4427 - accuracy: 0.7803\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.4401 - accuracy: 0.7860\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.4430 - accuracy: 0.7949\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4390 - accuracy: 0.7841\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.4370 - accuracy: 0.7936\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.4421 - accuracy: 0.7847\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4468 - accuracy: 0.7803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2_c4dXkhlMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ea51d4e-59b5-433b-90f1-dde9462cfdd4"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=80\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "10/10 [==============================] - 9s 865ms/step - loss: 0.4409 - accuracy: 0.7866\n",
            "Epoch 2/80\n",
            "10/10 [==============================] - 9s 885ms/step - loss: 0.4408 - accuracy: 0.7949\n",
            "Epoch 3/80\n",
            "10/10 [==============================] - 8s 844ms/step - loss: 0.4395 - accuracy: 0.7815\n",
            "Epoch 4/80\n",
            "10/10 [==============================] - 8s 836ms/step - loss: 0.4417 - accuracy: 0.7879\n",
            "Epoch 5/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.4445 - accuracy: 0.7815\n",
            "Epoch 6/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4394 - accuracy: 0.7898\n",
            "Epoch 7/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4241 - accuracy: 0.8089\n",
            "Epoch 8/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4285 - accuracy: 0.8032\n",
            "Epoch 9/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.4310 - accuracy: 0.7924\n",
            "Epoch 10/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4250 - accuracy: 0.7924\n",
            "Epoch 11/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4276 - accuracy: 0.7968\n",
            "Epoch 12/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.4217 - accuracy: 0.8064\n",
            "Epoch 13/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.4195 - accuracy: 0.7968\n",
            "Epoch 14/80\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.4278 - accuracy: 0.8025\n",
            "Epoch 15/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.4331 - accuracy: 0.7847\n",
            "Epoch 16/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4248 - accuracy: 0.7898\n",
            "Epoch 17/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4256 - accuracy: 0.7777\n",
            "Epoch 18/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4277 - accuracy: 0.8019\n",
            "Epoch 19/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.4194 - accuracy: 0.7949\n",
            "Epoch 20/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.4249 - accuracy: 0.7981\n",
            "Epoch 21/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4166 - accuracy: 0.7975\n",
            "Epoch 22/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.4270 - accuracy: 0.7936\n",
            "Epoch 23/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4222 - accuracy: 0.7892\n",
            "Epoch 24/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4204 - accuracy: 0.7987\n",
            "Epoch 25/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4137 - accuracy: 0.7949\n",
            "Epoch 26/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4158 - accuracy: 0.7962\n",
            "Epoch 27/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4092 - accuracy: 0.8045\n",
            "Epoch 28/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4181 - accuracy: 0.7949\n",
            "Epoch 29/80\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.4183 - accuracy: 0.8032\n",
            "Epoch 30/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4185 - accuracy: 0.8025\n",
            "Epoch 31/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4115 - accuracy: 0.7962\n",
            "Epoch 32/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.4314 - accuracy: 0.7987\n",
            "Epoch 33/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4148 - accuracy: 0.8076\n",
            "Epoch 34/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.4080 - accuracy: 0.7994\n",
            "Epoch 35/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4093 - accuracy: 0.8013\n",
            "Epoch 36/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.4125 - accuracy: 0.8006\n",
            "Epoch 37/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.3997 - accuracy: 0.8159\n",
            "Epoch 38/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.4069 - accuracy: 0.7962\n",
            "Epoch 39/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.4130 - accuracy: 0.8045\n",
            "Epoch 40/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.4149 - accuracy: 0.8025\n",
            "Epoch 41/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.4127 - accuracy: 0.7968\n",
            "Epoch 42/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.4044 - accuracy: 0.8102\n",
            "Epoch 43/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4014 - accuracy: 0.8096\n",
            "Epoch 44/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.4043 - accuracy: 0.8025\n",
            "Epoch 45/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.4043 - accuracy: 0.8032\n",
            "Epoch 46/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.4096 - accuracy: 0.8013\n",
            "Epoch 47/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.4055 - accuracy: 0.8045\n",
            "Epoch 48/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.4010 - accuracy: 0.8210\n",
            "Epoch 49/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.4066 - accuracy: 0.8096\n",
            "Epoch 50/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.4013 - accuracy: 0.7994\n",
            "Epoch 51/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.3970 - accuracy: 0.8089\n",
            "Epoch 52/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.3956 - accuracy: 0.8057\n",
            "Epoch 53/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.4074 - accuracy: 0.8083\n",
            "Epoch 54/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.3944 - accuracy: 0.8236\n",
            "Epoch 55/80\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.4002 - accuracy: 0.8140\n",
            "Epoch 56/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.3993 - accuracy: 0.8032\n",
            "Epoch 57/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.3966 - accuracy: 0.8210\n",
            "Epoch 58/80\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.4073 - accuracy: 0.8108\n",
            "Epoch 59/80\n",
            "10/10 [==============================] - 8s 848ms/step - loss: 0.3973 - accuracy: 0.8096\n",
            "Epoch 60/80\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.3941 - accuracy: 0.8127\n",
            "Epoch 61/80\n",
            "10/10 [==============================] - 8s 845ms/step - loss: 0.3921 - accuracy: 0.8121\n",
            "Epoch 62/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.3992 - accuracy: 0.8032\n",
            "Epoch 63/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.3857 - accuracy: 0.8159\n",
            "Epoch 64/80\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.3948 - accuracy: 0.8178\n",
            "Epoch 65/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.3960 - accuracy: 0.8115\n",
            "Epoch 66/80\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.3830 - accuracy: 0.8236\n",
            "Epoch 67/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.3952 - accuracy: 0.8178\n",
            "Epoch 68/80\n",
            "10/10 [==============================] - 9s 855ms/step - loss: 0.3820 - accuracy: 0.8268\n",
            "Epoch 69/80\n",
            "10/10 [==============================] - 9s 922ms/step - loss: 0.3843 - accuracy: 0.8261\n",
            "Epoch 70/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3846 - accuracy: 0.8166\n",
            "Epoch 71/80\n",
            "10/10 [==============================] - 9s 864ms/step - loss: 0.3887 - accuracy: 0.8121\n",
            "Epoch 72/80\n",
            "10/10 [==============================] - 8s 837ms/step - loss: 0.3729 - accuracy: 0.8331\n",
            "Epoch 73/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.3838 - accuracy: 0.8172\n",
            "Epoch 74/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.3812 - accuracy: 0.8191\n",
            "Epoch 75/80\n",
            "10/10 [==============================] - 8s 834ms/step - loss: 0.3815 - accuracy: 0.8312\n",
            "Epoch 76/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.3874 - accuracy: 0.8229\n",
            "Epoch 77/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.3830 - accuracy: 0.8274\n",
            "Epoch 78/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.3813 - accuracy: 0.8178\n",
            "Epoch 79/80\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.3748 - accuracy: 0.8293\n",
            "Epoch 80/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.3776 - accuracy: 0.8274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3UDCPzUsNhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6facfd5b-30de-4c0e-ea63-0a74e733b7fd"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=80\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "10/10 [==============================] - 8s 848ms/step - loss: 0.3769 - accuracy: 0.8268\n",
            "Epoch 2/80\n",
            "10/10 [==============================] - 9s 872ms/step - loss: 0.3752 - accuracy: 0.8268\n",
            "Epoch 3/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3666 - accuracy: 0.8274\n",
            "Epoch 4/80\n",
            "10/10 [==============================] - 8s 839ms/step - loss: 0.3862 - accuracy: 0.8248\n",
            "Epoch 5/80\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.3751 - accuracy: 0.8197\n",
            "Epoch 6/80\n",
            "10/10 [==============================] - 8s 846ms/step - loss: 0.3805 - accuracy: 0.8140\n",
            "Epoch 7/80\n",
            "10/10 [==============================] - 9s 857ms/step - loss: 0.3788 - accuracy: 0.8363\n",
            "Epoch 8/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.3681 - accuracy: 0.8210\n",
            "Epoch 9/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.3726 - accuracy: 0.8242\n",
            "Epoch 10/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3778 - accuracy: 0.8306\n",
            "Epoch 11/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.3694 - accuracy: 0.8287\n",
            "Epoch 12/80\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.3628 - accuracy: 0.8350\n",
            "Epoch 13/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3691 - accuracy: 0.8197\n",
            "Epoch 14/80\n",
            "10/10 [==============================] - 8s 847ms/step - loss: 0.3667 - accuracy: 0.8274\n",
            "Epoch 15/80\n",
            "10/10 [==============================] - 8s 837ms/step - loss: 0.3561 - accuracy: 0.8478\n",
            "Epoch 16/80\n",
            "10/10 [==============================] - 8s 845ms/step - loss: 0.3633 - accuracy: 0.8217\n",
            "Epoch 17/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3712 - accuracy: 0.8261\n",
            "Epoch 18/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3638 - accuracy: 0.8376\n",
            "Epoch 19/80\n",
            "10/10 [==============================] - 8s 837ms/step - loss: 0.3659 - accuracy: 0.8363\n",
            "Epoch 20/80\n",
            "10/10 [==============================] - 8s 847ms/step - loss: 0.3643 - accuracy: 0.8395\n",
            "Epoch 21/80\n",
            "10/10 [==============================] - 9s 861ms/step - loss: 0.3726 - accuracy: 0.8236\n",
            "Epoch 22/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3614 - accuracy: 0.8306\n",
            "Epoch 23/80\n",
            "10/10 [==============================] - 8s 842ms/step - loss: 0.3788 - accuracy: 0.8287\n",
            "Epoch 24/80\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.3616 - accuracy: 0.8344\n",
            "Epoch 25/80\n",
            "10/10 [==============================] - 8s 836ms/step - loss: 0.3619 - accuracy: 0.8427\n",
            "Epoch 26/80\n",
            "10/10 [==============================] - 9s 897ms/step - loss: 0.3630 - accuracy: 0.8389\n",
            "Epoch 27/80\n",
            "10/10 [==============================] - 9s 889ms/step - loss: 0.3537 - accuracy: 0.8389\n",
            "Epoch 28/80\n",
            "10/10 [==============================] - 9s 860ms/step - loss: 0.3615 - accuracy: 0.8344\n",
            "Epoch 29/80\n",
            "10/10 [==============================] - 9s 884ms/step - loss: 0.3601 - accuracy: 0.8306\n",
            "Epoch 30/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3527 - accuracy: 0.8459\n",
            "Epoch 31/80\n",
            "10/10 [==============================] - 9s 857ms/step - loss: 0.3570 - accuracy: 0.8452\n",
            "Epoch 32/80\n",
            "10/10 [==============================] - 9s 858ms/step - loss: 0.3525 - accuracy: 0.8287\n",
            "Epoch 33/80\n",
            "10/10 [==============================] - 9s 857ms/step - loss: 0.3556 - accuracy: 0.8389\n",
            "Epoch 34/80\n",
            "10/10 [==============================] - 8s 850ms/step - loss: 0.3443 - accuracy: 0.8439\n",
            "Epoch 35/80\n",
            "10/10 [==============================] - 9s 856ms/step - loss: 0.3551 - accuracy: 0.8389\n",
            "Epoch 36/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.3608 - accuracy: 0.8376\n",
            "Epoch 37/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3512 - accuracy: 0.8439\n",
            "Epoch 38/80\n",
            "10/10 [==============================] - 8s 842ms/step - loss: 0.3555 - accuracy: 0.8471\n",
            "Epoch 39/80\n",
            "10/10 [==============================] - 9s 862ms/step - loss: 0.3494 - accuracy: 0.8401\n",
            "Epoch 40/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3538 - accuracy: 0.8376\n",
            "Epoch 41/80\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.3673 - accuracy: 0.8306\n",
            "Epoch 42/80\n",
            "10/10 [==============================] - 9s 862ms/step - loss: 0.3509 - accuracy: 0.8433\n",
            "Epoch 43/80\n",
            "10/10 [==============================] - 9s 870ms/step - loss: 0.3513 - accuracy: 0.8369\n",
            "Epoch 44/80\n",
            "10/10 [==============================] - 9s 872ms/step - loss: 0.3433 - accuracy: 0.8490\n",
            "Epoch 45/80\n",
            "10/10 [==============================] - 9s 874ms/step - loss: 0.3372 - accuracy: 0.8484\n",
            "Epoch 46/80\n",
            "10/10 [==============================] - 9s 888ms/step - loss: 0.3413 - accuracy: 0.8427\n",
            "Epoch 47/80\n",
            "10/10 [==============================] - 9s 872ms/step - loss: 0.3510 - accuracy: 0.8452\n",
            "Epoch 48/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3423 - accuracy: 0.8605\n",
            "Epoch 49/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3390 - accuracy: 0.8554\n",
            "Epoch 50/80\n",
            "10/10 [==============================] - 9s 860ms/step - loss: 0.3432 - accuracy: 0.8414\n",
            "Epoch 51/80\n",
            "10/10 [==============================] - 9s 911ms/step - loss: 0.3426 - accuracy: 0.8401\n",
            "Epoch 52/80\n",
            "10/10 [==============================] - 9s 885ms/step - loss: 0.3436 - accuracy: 0.8395\n",
            "Epoch 53/80\n",
            "10/10 [==============================] - 9s 896ms/step - loss: 0.3295 - accuracy: 0.8471\n",
            "Epoch 54/80\n",
            "10/10 [==============================] - 9s 881ms/step - loss: 0.3346 - accuracy: 0.8529\n",
            "Epoch 55/80\n",
            "10/10 [==============================] - 9s 854ms/step - loss: 0.3362 - accuracy: 0.8516\n",
            "Epoch 56/80\n",
            "10/10 [==============================] - 9s 854ms/step - loss: 0.3234 - accuracy: 0.8611\n",
            "Epoch 57/80\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.3393 - accuracy: 0.8446\n",
            "Epoch 58/80\n",
            "10/10 [==============================] - 9s 858ms/step - loss: 0.3338 - accuracy: 0.8471\n",
            "Epoch 59/80\n",
            "10/10 [==============================] - 8s 850ms/step - loss: 0.3252 - accuracy: 0.8624\n",
            "Epoch 60/80\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.3291 - accuracy: 0.8561\n",
            "Epoch 61/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3414 - accuracy: 0.8459\n",
            "Epoch 62/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3385 - accuracy: 0.8471\n",
            "Epoch 63/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3332 - accuracy: 0.8414\n",
            "Epoch 64/80\n",
            "10/10 [==============================] - 8s 844ms/step - loss: 0.3234 - accuracy: 0.8497\n",
            "Epoch 65/80\n",
            "10/10 [==============================] - 9s 858ms/step - loss: 0.3314 - accuracy: 0.8516\n",
            "Epoch 66/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3292 - accuracy: 0.8522\n",
            "Epoch 67/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3335 - accuracy: 0.8592\n",
            "Epoch 68/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3151 - accuracy: 0.8650\n",
            "Epoch 69/80\n",
            "10/10 [==============================] - 9s 861ms/step - loss: 0.3334 - accuracy: 0.8490\n",
            "Epoch 70/80\n",
            "10/10 [==============================] - 9s 870ms/step - loss: 0.3161 - accuracy: 0.8605\n",
            "Epoch 71/80\n",
            "10/10 [==============================] - 9s 858ms/step - loss: 0.3279 - accuracy: 0.8548\n",
            "Epoch 72/80\n",
            "10/10 [==============================] - 8s 849ms/step - loss: 0.3200 - accuracy: 0.8669\n",
            "Epoch 73/80\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.3346 - accuracy: 0.8522\n",
            "Epoch 74/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3174 - accuracy: 0.8605\n",
            "Epoch 75/80\n",
            "10/10 [==============================] - 9s 853ms/step - loss: 0.3258 - accuracy: 0.8611\n",
            "Epoch 76/80\n",
            "10/10 [==============================] - 8s 842ms/step - loss: 0.3255 - accuracy: 0.8580\n",
            "Epoch 77/80\n",
            "10/10 [==============================] - 9s 851ms/step - loss: 0.3169 - accuracy: 0.8701\n",
            "Epoch 78/80\n",
            "10/10 [==============================] - 8s 845ms/step - loss: 0.3193 - accuracy: 0.8541\n",
            "Epoch 79/80\n",
            "10/10 [==============================] - 9s 862ms/step - loss: 0.3239 - accuracy: 0.8586\n",
            "Epoch 80/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.3324 - accuracy: 0.8516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sjz6vW1vk4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee26ee73-fb84-47e7-cee7-05e39307cef7"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=80\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.3272 - accuracy: 0.8592\n",
            "Epoch 2/80\n",
            "10/10 [==============================] - 8s 848ms/step - loss: 0.3301 - accuracy: 0.8586\n",
            "Epoch 3/80\n",
            "10/10 [==============================] - 8s 834ms/step - loss: 0.3152 - accuracy: 0.8592\n",
            "Epoch 4/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.3105 - accuracy: 0.8720\n",
            "Epoch 5/80\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.3319 - accuracy: 0.8484\n",
            "Epoch 6/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.3106 - accuracy: 0.8618\n",
            "Epoch 7/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.3122 - accuracy: 0.8554\n",
            "Epoch 8/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.3151 - accuracy: 0.8592\n",
            "Epoch 9/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.3179 - accuracy: 0.8605\n",
            "Epoch 10/80\n",
            "10/10 [==============================] - 8s 836ms/step - loss: 0.3115 - accuracy: 0.8675\n",
            "Epoch 11/80\n",
            "10/10 [==============================] - 8s 834ms/step - loss: 0.3109 - accuracy: 0.8599\n",
            "Epoch 12/80\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.3233 - accuracy: 0.8637\n",
            "Epoch 13/80\n",
            "10/10 [==============================] - 9s 862ms/step - loss: 0.3050 - accuracy: 0.8726\n",
            "Epoch 14/80\n",
            "10/10 [==============================] - 8s 848ms/step - loss: 0.3082 - accuracy: 0.8707\n",
            "Epoch 15/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.3203 - accuracy: 0.8554\n",
            "Epoch 16/80\n",
            "10/10 [==============================] - 8s 842ms/step - loss: 0.3056 - accuracy: 0.8650\n",
            "Epoch 17/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.3152 - accuracy: 0.8618\n",
            "Epoch 18/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.2992 - accuracy: 0.8745\n",
            "Epoch 19/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.3140 - accuracy: 0.8643\n",
            "Epoch 20/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.3142 - accuracy: 0.8643\n",
            "Epoch 21/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.3036 - accuracy: 0.8631\n",
            "Epoch 22/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2940 - accuracy: 0.8790\n",
            "Epoch 23/80\n",
            "10/10 [==============================] - 8s 836ms/step - loss: 0.2977 - accuracy: 0.8713\n",
            "Epoch 24/80\n",
            "10/10 [==============================] - 8s 839ms/step - loss: 0.3052 - accuracy: 0.8669\n",
            "Epoch 25/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2972 - accuracy: 0.8822\n",
            "Epoch 26/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2992 - accuracy: 0.8815\n",
            "Epoch 27/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2852 - accuracy: 0.8745\n",
            "Epoch 28/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.2850 - accuracy: 0.8752\n",
            "Epoch 29/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.2943 - accuracy: 0.8809\n",
            "Epoch 30/80\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.3067 - accuracy: 0.8669\n",
            "Epoch 31/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.3098 - accuracy: 0.8637\n",
            "Epoch 32/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.3018 - accuracy: 0.8726\n",
            "Epoch 33/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2877 - accuracy: 0.8771\n",
            "Epoch 34/80\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.2944 - accuracy: 0.8752\n",
            "Epoch 35/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.2928 - accuracy: 0.8822\n",
            "Epoch 36/80\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.2909 - accuracy: 0.8739\n",
            "Epoch 37/80\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.2913 - accuracy: 0.8707\n",
            "Epoch 38/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.2904 - accuracy: 0.8707\n",
            "Epoch 39/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.2834 - accuracy: 0.8809\n",
            "Epoch 40/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2966 - accuracy: 0.8720\n",
            "Epoch 41/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2939 - accuracy: 0.8783\n",
            "Epoch 42/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.2942 - accuracy: 0.8713\n",
            "Epoch 43/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.2972 - accuracy: 0.8682\n",
            "Epoch 44/80\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.2843 - accuracy: 0.8803\n",
            "Epoch 45/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2818 - accuracy: 0.8815\n",
            "Epoch 46/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2790 - accuracy: 0.8809\n",
            "Epoch 47/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2881 - accuracy: 0.8713\n",
            "Epoch 48/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2877 - accuracy: 0.8707\n",
            "Epoch 49/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.2786 - accuracy: 0.8790\n",
            "Epoch 50/80\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.2694 - accuracy: 0.8860\n",
            "Epoch 51/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2756 - accuracy: 0.8879\n",
            "Epoch 52/80\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.2846 - accuracy: 0.8841\n",
            "Epoch 53/80\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.2815 - accuracy: 0.8815\n",
            "Epoch 54/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2807 - accuracy: 0.8745\n",
            "Epoch 55/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.2753 - accuracy: 0.8860\n",
            "Epoch 56/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2752 - accuracy: 0.8847\n",
            "Epoch 57/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2647 - accuracy: 0.8924\n",
            "Epoch 58/80\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.2809 - accuracy: 0.8879\n",
            "Epoch 59/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2742 - accuracy: 0.8866\n",
            "Epoch 60/80\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.2667 - accuracy: 0.8860\n",
            "Epoch 61/80\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.2634 - accuracy: 0.8885\n",
            "Epoch 62/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.2631 - accuracy: 0.8898\n",
            "Epoch 63/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2764 - accuracy: 0.8847\n",
            "Epoch 64/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2681 - accuracy: 0.8860\n",
            "Epoch 65/80\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.2606 - accuracy: 0.8924\n",
            "Epoch 66/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2692 - accuracy: 0.8904\n",
            "Epoch 67/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.2627 - accuracy: 0.8860\n",
            "Epoch 68/80\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.2721 - accuracy: 0.8841\n",
            "Epoch 69/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2650 - accuracy: 0.8898\n",
            "Epoch 70/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2683 - accuracy: 0.8828\n",
            "Epoch 71/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2658 - accuracy: 0.8930\n",
            "Epoch 72/80\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.2655 - accuracy: 0.8904\n",
            "Epoch 73/80\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.2605 - accuracy: 0.8930\n",
            "Epoch 74/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2631 - accuracy: 0.8892\n",
            "Epoch 75/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.2734 - accuracy: 0.8815\n",
            "Epoch 76/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2516 - accuracy: 0.8975\n",
            "Epoch 77/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2598 - accuracy: 0.8815\n",
            "Epoch 78/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2586 - accuracy: 0.8943\n",
            "Epoch 79/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2672 - accuracy: 0.8885\n",
            "Epoch 80/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2618 - accuracy: 0.8822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zz-Q2P_ym0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0da9f12-933c-4802-af18-9d1a16eb0e17"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=80\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "10/10 [==============================] - 8s 843ms/step - loss: 0.2581 - accuracy: 0.8962\n",
            "Epoch 2/80\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.2626 - accuracy: 0.8866\n",
            "Epoch 3/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2559 - accuracy: 0.8943\n",
            "Epoch 4/80\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.2631 - accuracy: 0.8854\n",
            "Epoch 5/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.2531 - accuracy: 0.8917\n",
            "Epoch 6/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2658 - accuracy: 0.8924\n",
            "Epoch 7/80\n",
            "10/10 [==============================] - 8s 839ms/step - loss: 0.2610 - accuracy: 0.8892\n",
            "Epoch 8/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2591 - accuracy: 0.8924\n",
            "Epoch 9/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2474 - accuracy: 0.9000\n",
            "Epoch 10/80\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.2670 - accuracy: 0.8917\n",
            "Epoch 11/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2618 - accuracy: 0.8873\n",
            "Epoch 12/80\n",
            "10/10 [==============================] - 8s 841ms/step - loss: 0.2521 - accuracy: 0.8968\n",
            "Epoch 13/80\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.2564 - accuracy: 0.8975\n",
            "Epoch 14/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2560 - accuracy: 0.8936\n",
            "Epoch 15/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2413 - accuracy: 0.9000\n",
            "Epoch 16/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2523 - accuracy: 0.8911\n",
            "Epoch 17/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2374 - accuracy: 0.9089\n",
            "Epoch 18/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2467 - accuracy: 0.9000\n",
            "Epoch 19/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2493 - accuracy: 0.8917\n",
            "Epoch 20/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2490 - accuracy: 0.9013\n",
            "Epoch 21/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2488 - accuracy: 0.9006\n",
            "Epoch 22/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2403 - accuracy: 0.8987\n",
            "Epoch 23/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2269 - accuracy: 0.8987\n",
            "Epoch 24/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.2428 - accuracy: 0.9038\n",
            "Epoch 25/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2382 - accuracy: 0.8955\n",
            "Epoch 26/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.2553 - accuracy: 0.8975\n",
            "Epoch 27/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2476 - accuracy: 0.8924\n",
            "Epoch 28/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.2314 - accuracy: 0.9045\n",
            "Epoch 29/80\n",
            "10/10 [==============================] - 8s 840ms/step - loss: 0.2319 - accuracy: 0.9096\n",
            "Epoch 30/80\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.2435 - accuracy: 0.8968\n",
            "Epoch 31/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.2343 - accuracy: 0.9070\n",
            "Epoch 32/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2259 - accuracy: 0.9172\n",
            "Epoch 33/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.2341 - accuracy: 0.8994\n",
            "Epoch 34/80\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2369 - accuracy: 0.9006\n",
            "Epoch 35/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2332 - accuracy: 0.9057\n",
            "Epoch 36/80\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.2341 - accuracy: 0.9102\n",
            "Epoch 37/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2225 - accuracy: 0.9115\n",
            "Epoch 38/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2279 - accuracy: 0.9134\n",
            "Epoch 39/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2354 - accuracy: 0.9025\n",
            "Epoch 40/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.2242 - accuracy: 0.9045\n",
            "Epoch 41/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2209 - accuracy: 0.9172\n",
            "Epoch 42/80\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.2252 - accuracy: 0.9064\n",
            "Epoch 43/80\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.2328 - accuracy: 0.9006\n",
            "Epoch 44/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.2091 - accuracy: 0.9236\n",
            "Epoch 45/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2210 - accuracy: 0.9064\n",
            "Epoch 46/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2252 - accuracy: 0.9064\n",
            "Epoch 47/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2378 - accuracy: 0.9038\n",
            "Epoch 48/80\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.2210 - accuracy: 0.9089\n",
            "Epoch 49/80\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.2163 - accuracy: 0.9115\n",
            "Epoch 50/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.2283 - accuracy: 0.9051\n",
            "Epoch 51/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2303 - accuracy: 0.9102\n",
            "Epoch 52/80\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.2211 - accuracy: 0.9076\n",
            "Epoch 53/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2114 - accuracy: 0.9127\n",
            "Epoch 54/80\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.2119 - accuracy: 0.9159\n",
            "Epoch 55/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2212 - accuracy: 0.9051\n",
            "Epoch 56/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2128 - accuracy: 0.9121\n",
            "Epoch 57/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2214 - accuracy: 0.9076\n",
            "Epoch 58/80\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.2261 - accuracy: 0.9159\n",
            "Epoch 59/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2109 - accuracy: 0.9146\n",
            "Epoch 60/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2160 - accuracy: 0.9140\n",
            "Epoch 61/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2142 - accuracy: 0.9153\n",
            "Epoch 62/80\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.2070 - accuracy: 0.9134\n",
            "Epoch 63/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2105 - accuracy: 0.9102\n",
            "Epoch 64/80\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.1960 - accuracy: 0.9280\n",
            "Epoch 65/80\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.2216 - accuracy: 0.9146\n",
            "Epoch 66/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2096 - accuracy: 0.9172\n",
            "Epoch 67/80\n",
            "10/10 [==============================] - 8s 837ms/step - loss: 0.1945 - accuracy: 0.9178\n",
            "Epoch 68/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2090 - accuracy: 0.9153\n",
            "Epoch 69/80\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.2209 - accuracy: 0.9045\n",
            "Epoch 70/80\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.2172 - accuracy: 0.9070\n",
            "Epoch 71/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2015 - accuracy: 0.9248\n",
            "Epoch 72/80\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.2091 - accuracy: 0.9146\n",
            "Epoch 73/80\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.2106 - accuracy: 0.9178\n",
            "Epoch 74/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2012 - accuracy: 0.9185\n",
            "Epoch 75/80\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.2074 - accuracy: 0.9248\n",
            "Epoch 76/80\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.2046 - accuracy: 0.9185\n",
            "Epoch 77/80\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1891 - accuracy: 0.9350\n",
            "Epoch 78/80\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.1992 - accuracy: 0.9204\n",
            "Epoch 79/80\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.2014 - accuracy: 0.9255\n",
            "Epoch 80/80\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.2090 - accuracy: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSquA8sc1xz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a53c3cc-cdb0-4a74-d15f-27d0b63da180"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples//train_batchsize, \n",
        "    epochs=180\n",
        "    \n",
        "    )\n",
        "model.save('preprocess_mag_scipy_Srkws.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/180\n",
            "10/10 [==============================] - 9s 850ms/step - loss: 0.1947 - accuracy: 0.9210\n",
            "Epoch 2/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.2001 - accuracy: 0.9191\n",
            "Epoch 3/180\n",
            "10/10 [==============================] - 8s 838ms/step - loss: 0.1867 - accuracy: 0.9312\n",
            "Epoch 4/180\n",
            "10/10 [==============================] - 8s 834ms/step - loss: 0.1997 - accuracy: 0.9166\n",
            "Epoch 5/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1851 - accuracy: 0.9350\n",
            "Epoch 6/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1834 - accuracy: 0.9280\n",
            "Epoch 7/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1800 - accuracy: 0.9274\n",
            "Epoch 8/180\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.1871 - accuracy: 0.9261\n",
            "Epoch 9/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1910 - accuracy: 0.9293\n",
            "Epoch 10/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1861 - accuracy: 0.9236\n",
            "Epoch 11/180\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.1892 - accuracy: 0.9210\n",
            "Epoch 12/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1768 - accuracy: 0.9363\n",
            "Epoch 13/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1859 - accuracy: 0.9255\n",
            "Epoch 14/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1963 - accuracy: 0.9236\n",
            "Epoch 15/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1844 - accuracy: 0.9287\n",
            "Epoch 16/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1827 - accuracy: 0.9338\n",
            "Epoch 17/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1880 - accuracy: 0.9217\n",
            "Epoch 18/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1735 - accuracy: 0.9338\n",
            "Epoch 19/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1877 - accuracy: 0.9236\n",
            "Epoch 20/180\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.1817 - accuracy: 0.9287\n",
            "Epoch 21/180\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.1822 - accuracy: 0.9229\n",
            "Epoch 22/180\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.1821 - accuracy: 0.9261\n",
            "Epoch 23/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1903 - accuracy: 0.9268\n",
            "Epoch 24/180\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.1822 - accuracy: 0.9357\n",
            "Epoch 25/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1778 - accuracy: 0.9338\n",
            "Epoch 26/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1705 - accuracy: 0.9338\n",
            "Epoch 27/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1730 - accuracy: 0.9299\n",
            "Epoch 28/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1699 - accuracy: 0.9350\n",
            "Epoch 29/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1776 - accuracy: 0.9331\n",
            "Epoch 30/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1725 - accuracy: 0.9395\n",
            "Epoch 31/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1809 - accuracy: 0.9299\n",
            "Epoch 32/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1670 - accuracy: 0.9408\n",
            "Epoch 33/180\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.1601 - accuracy: 0.9395\n",
            "Epoch 34/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1779 - accuracy: 0.9274\n",
            "Epoch 35/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1767 - accuracy: 0.9293\n",
            "Epoch 36/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1746 - accuracy: 0.9306\n",
            "Epoch 37/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1597 - accuracy: 0.9395\n",
            "Epoch 38/180\n",
            "10/10 [==============================] - 8s 808ms/step - loss: 0.1719 - accuracy: 0.9318\n",
            "Epoch 39/180\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.1438 - accuracy: 0.9535\n",
            "Epoch 40/180\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.1879 - accuracy: 0.9287\n",
            "Epoch 41/180\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.1637 - accuracy: 0.9389\n",
            "Epoch 42/180\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.1635 - accuracy: 0.9363\n",
            "Epoch 43/180\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.1694 - accuracy: 0.9382\n",
            "Epoch 44/180\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.1707 - accuracy: 0.9357\n",
            "Epoch 45/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1729 - accuracy: 0.9306\n",
            "Epoch 46/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1806 - accuracy: 0.9325\n",
            "Epoch 47/180\n",
            "10/10 [==============================] - 8s 808ms/step - loss: 0.1739 - accuracy: 0.9325\n",
            "Epoch 48/180\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.1722 - accuracy: 0.9318\n",
            "Epoch 49/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1706 - accuracy: 0.9427\n",
            "Epoch 50/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1799 - accuracy: 0.9274\n",
            "Epoch 51/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1488 - accuracy: 0.9484\n",
            "Epoch 52/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1602 - accuracy: 0.9382\n",
            "Epoch 53/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1601 - accuracy: 0.9382\n",
            "Epoch 54/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1637 - accuracy: 0.9420\n",
            "Epoch 55/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1615 - accuracy: 0.9382\n",
            "Epoch 56/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1620 - accuracy: 0.9376\n",
            "Epoch 57/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1577 - accuracy: 0.9369\n",
            "Epoch 58/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1610 - accuracy: 0.9344\n",
            "Epoch 59/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1529 - accuracy: 0.9401\n",
            "Epoch 60/180\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.1630 - accuracy: 0.9357\n",
            "Epoch 61/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1635 - accuracy: 0.9338\n",
            "Epoch 62/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1454 - accuracy: 0.9490\n",
            "Epoch 63/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1808 - accuracy: 0.9274\n",
            "Epoch 64/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1565 - accuracy: 0.9376\n",
            "Epoch 65/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1549 - accuracy: 0.9433\n",
            "Epoch 66/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1468 - accuracy: 0.9439\n",
            "Epoch 67/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1500 - accuracy: 0.9471\n",
            "Epoch 68/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1725 - accuracy: 0.9287\n",
            "Epoch 69/180\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.1645 - accuracy: 0.9363\n",
            "Epoch 70/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1636 - accuracy: 0.9350\n",
            "Epoch 71/180\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.1507 - accuracy: 0.9465\n",
            "Epoch 72/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1497 - accuracy: 0.9420\n",
            "Epoch 73/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1468 - accuracy: 0.9471\n",
            "Epoch 74/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1477 - accuracy: 0.9439\n",
            "Epoch 75/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1523 - accuracy: 0.9389\n",
            "Epoch 76/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1400 - accuracy: 0.9490\n",
            "Epoch 77/180\n",
            "10/10 [==============================] - 8s 808ms/step - loss: 0.1377 - accuracy: 0.9459\n",
            "Epoch 78/180\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.1558 - accuracy: 0.9420\n",
            "Epoch 79/180\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.1403 - accuracy: 0.9433\n",
            "Epoch 80/180\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.1406 - accuracy: 0.9490\n",
            "Epoch 81/180\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.1517 - accuracy: 0.9433\n",
            "Epoch 82/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1561 - accuracy: 0.9452\n",
            "Epoch 83/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1379 - accuracy: 0.9471\n",
            "Epoch 84/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1423 - accuracy: 0.9510\n",
            "Epoch 85/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1515 - accuracy: 0.9433\n",
            "Epoch 86/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1531 - accuracy: 0.9389\n",
            "Epoch 87/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1342 - accuracy: 0.9529\n",
            "Epoch 88/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1419 - accuracy: 0.9484\n",
            "Epoch 89/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1509 - accuracy: 0.9490\n",
            "Epoch 90/180\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.1309 - accuracy: 0.9510\n",
            "Epoch 91/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1526 - accuracy: 0.9420\n",
            "Epoch 92/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1410 - accuracy: 0.9427\n",
            "Epoch 93/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1413 - accuracy: 0.9503\n",
            "Epoch 94/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1409 - accuracy: 0.9465\n",
            "Epoch 95/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1315 - accuracy: 0.9586\n",
            "Epoch 96/180\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.1378 - accuracy: 0.9516\n",
            "Epoch 97/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1328 - accuracy: 0.9516\n",
            "Epoch 98/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1251 - accuracy: 0.9548\n",
            "Epoch 99/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1349 - accuracy: 0.9452\n",
            "Epoch 100/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1443 - accuracy: 0.9433\n",
            "Epoch 101/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1506 - accuracy: 0.9420\n",
            "Epoch 102/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1400 - accuracy: 0.9503\n",
            "Epoch 103/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1257 - accuracy: 0.9599\n",
            "Epoch 104/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1247 - accuracy: 0.9554\n",
            "Epoch 105/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1292 - accuracy: 0.9497\n",
            "Epoch 106/180\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.1255 - accuracy: 0.9516\n",
            "Epoch 107/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1409 - accuracy: 0.9433\n",
            "Epoch 108/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1335 - accuracy: 0.9484\n",
            "Epoch 109/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1266 - accuracy: 0.9529\n",
            "Epoch 110/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1192 - accuracy: 0.9624\n",
            "Epoch 111/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1250 - accuracy: 0.9573\n",
            "Epoch 112/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1237 - accuracy: 0.9567\n",
            "Epoch 113/180\n",
            "10/10 [==============================] - 8s 810ms/step - loss: 0.1194 - accuracy: 0.9605\n",
            "Epoch 114/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1218 - accuracy: 0.9548\n",
            "Epoch 115/180\n",
            "10/10 [==============================] - 8s 809ms/step - loss: 0.1256 - accuracy: 0.9503\n",
            "Epoch 116/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1310 - accuracy: 0.9465\n",
            "Epoch 117/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1320 - accuracy: 0.9510\n",
            "Epoch 118/180\n",
            "10/10 [==============================] - 8s 835ms/step - loss: 0.1140 - accuracy: 0.9599\n",
            "Epoch 119/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1157 - accuracy: 0.9624\n",
            "Epoch 120/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1231 - accuracy: 0.9548\n",
            "Epoch 121/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1264 - accuracy: 0.9471\n",
            "Epoch 122/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1338 - accuracy: 0.9535\n",
            "Epoch 123/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1183 - accuracy: 0.9611\n",
            "Epoch 124/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1206 - accuracy: 0.9561\n",
            "Epoch 125/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1220 - accuracy: 0.9592\n",
            "Epoch 126/180\n",
            "10/10 [==============================] - 8s 818ms/step - loss: 0.1177 - accuracy: 0.9611\n",
            "Epoch 127/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1199 - accuracy: 0.9573\n",
            "Epoch 128/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1249 - accuracy: 0.9567\n",
            "Epoch 129/180\n",
            "10/10 [==============================] - 8s 826ms/step - loss: 0.1112 - accuracy: 0.9605\n",
            "Epoch 130/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1108 - accuracy: 0.9669\n",
            "Epoch 131/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1102 - accuracy: 0.9618\n",
            "Epoch 132/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1266 - accuracy: 0.9548\n",
            "Epoch 133/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1156 - accuracy: 0.9643\n",
            "Epoch 134/180\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.1252 - accuracy: 0.9497\n",
            "Epoch 135/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1066 - accuracy: 0.9637\n",
            "Epoch 136/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1208 - accuracy: 0.9573\n",
            "Epoch 137/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1127 - accuracy: 0.9605\n",
            "Epoch 138/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1081 - accuracy: 0.9675\n",
            "Epoch 139/180\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.1266 - accuracy: 0.9529\n",
            "Epoch 140/180\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.0965 - accuracy: 0.9713\n",
            "Epoch 141/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1085 - accuracy: 0.9611\n",
            "Epoch 142/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1155 - accuracy: 0.9561\n",
            "Epoch 143/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1185 - accuracy: 0.9535\n",
            "Epoch 144/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1198 - accuracy: 0.9586\n",
            "Epoch 145/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1131 - accuracy: 0.9580\n",
            "Epoch 146/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1014 - accuracy: 0.9669\n",
            "Epoch 147/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.1138 - accuracy: 0.9580\n",
            "Epoch 148/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1178 - accuracy: 0.9580\n",
            "Epoch 149/180\n",
            "10/10 [==============================] - 8s 822ms/step - loss: 0.1091 - accuracy: 0.9611\n",
            "Epoch 150/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.1011 - accuracy: 0.9631\n",
            "Epoch 151/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1090 - accuracy: 0.9631\n",
            "Epoch 152/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1017 - accuracy: 0.9656\n",
            "Epoch 153/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.1134 - accuracy: 0.9580\n",
            "Epoch 154/180\n",
            "10/10 [==============================] - 8s 808ms/step - loss: 0.0979 - accuracy: 0.9707\n",
            "Epoch 155/180\n",
            "10/10 [==============================] - 8s 839ms/step - loss: 0.1056 - accuracy: 0.9631\n",
            "Epoch 156/180\n",
            "10/10 [==============================] - 8s 828ms/step - loss: 0.1021 - accuracy: 0.9631\n",
            "Epoch 157/180\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.1137 - accuracy: 0.9605\n",
            "Epoch 158/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.0961 - accuracy: 0.9688\n",
            "Epoch 159/180\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.1021 - accuracy: 0.9605\n",
            "Epoch 160/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1007 - accuracy: 0.9637\n",
            "Epoch 161/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.0950 - accuracy: 0.9675\n",
            "Epoch 162/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1035 - accuracy: 0.9599\n",
            "Epoch 163/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.1055 - accuracy: 0.9656\n",
            "Epoch 164/180\n",
            "10/10 [==============================] - 8s 814ms/step - loss: 0.0893 - accuracy: 0.9726\n",
            "Epoch 165/180\n",
            "10/10 [==============================] - 8s 813ms/step - loss: 0.1044 - accuracy: 0.9631\n",
            "Epoch 166/180\n",
            "10/10 [==============================] - 8s 812ms/step - loss: 0.1022 - accuracy: 0.9650\n",
            "Epoch 167/180\n",
            "10/10 [==============================] - 8s 830ms/step - loss: 0.0945 - accuracy: 0.9662\n",
            "Epoch 168/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1032 - accuracy: 0.9586\n",
            "Epoch 169/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.0984 - accuracy: 0.9688\n",
            "Epoch 170/180\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.0951 - accuracy: 0.9650\n",
            "Epoch 171/180\n",
            "10/10 [==============================] - 8s 820ms/step - loss: 0.1001 - accuracy: 0.9669\n",
            "Epoch 172/180\n",
            "10/10 [==============================] - 8s 824ms/step - loss: 0.0865 - accuracy: 0.9777\n",
            "Epoch 173/180\n",
            "10/10 [==============================] - 8s 811ms/step - loss: 0.1119 - accuracy: 0.9580\n",
            "Epoch 174/180\n",
            "10/10 [==============================] - 8s 819ms/step - loss: 0.1002 - accuracy: 0.9669\n",
            "Epoch 175/180\n",
            "10/10 [==============================] - 8s 815ms/step - loss: 0.1030 - accuracy: 0.9599\n",
            "Epoch 176/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.0883 - accuracy: 0.9688\n",
            "Epoch 177/180\n",
            "10/10 [==============================] - 8s 823ms/step - loss: 0.0953 - accuracy: 0.9694\n",
            "Epoch 178/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.1019 - accuracy: 0.9631\n",
            "Epoch 179/180\n",
            "10/10 [==============================] - 8s 817ms/step - loss: 0.0944 - accuracy: 0.9656\n",
            "Epoch 180/180\n",
            "10/10 [==============================] - 8s 816ms/step - loss: 0.1041 - accuracy: 0.9631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI8kti_KvS7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4304a78-99b9-43f2-bdd9-e2c7b456e9d0"
      },
      "source": [
        "!unzip \"/content/test2.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test2.zip\n",
            "   creating: test/\n",
            "   creating: test/nocalls/\n",
            "  inflating: test/nocalls/neg_calls_pod3222.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3217.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3238.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3253.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3211.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3272.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3215.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3242.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3271.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3214.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3257.png  \n",
            "  inflating: test/nocalls/neg_calls_pod321.png  \n",
            "  inflating: test/nocalls/neg_calls_pod32100.png  \n",
            "  inflating: test/nocalls/neg_calls_pod328.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3239.png  \n",
            "  inflating: test/nocalls/neg_calls_pod322.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3245.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3255.png  \n",
            "  inflating: test/nocalls/neg_calls_pod327.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3299.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3279.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3228.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3276.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3250.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3282.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3265.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3278.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3230.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3221.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3231.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3287.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3294.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3273.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3260.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3258.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3225.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3249.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3295.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3220.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3275.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3210.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3280.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3227.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3291.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3263.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3261.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3241.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3284.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3267.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3251.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3289.png  \n",
            "  inflating: test/nocalls/neg_calls_pod329.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3235.png  \n",
            "  inflating: test/nocalls/neg_calls_pod324.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3292.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3293.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3252.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3246.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3243.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3262.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3264.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3247.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3237.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3219.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3268.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3216.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3226.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3296.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3254.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3288.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3248.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3244.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3224.png  \n",
            "  inflating: test/nocalls/neg_calls_pod325.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3256.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3286.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3269.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3259.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3298.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3234.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3240.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3212.png  \n",
            "  inflating: test/nocalls/neg_calls_pod323.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3236.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3297.png  \n",
            "  inflating: test/nocalls/neg_calls_pod326.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3223.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3270.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3274.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3290.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3277.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3229.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3213.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3285.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3283.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3232.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3233.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3266.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3281.png  \n",
            "  inflating: test/nocalls/neg_calls_pod3218.png  \n",
            "   creating: test/calls/\n",
            "  inflating: test/calls/calls_pod352.png  \n",
            "  inflating: test/calls/calls_pod399.png  \n",
            "  inflating: test/calls/calls_pod393.png  \n",
            "  inflating: test/calls/calls_pod338.png  \n",
            "  inflating: test/calls/calls_pod346.png  \n",
            "  inflating: test/calls/calls_pod362.png  \n",
            "  inflating: test/calls/calls_pod369.png  \n",
            "  inflating: test/calls/calls_pod327.png  \n",
            "  inflating: test/calls/calls_pod38.png  \n",
            "  inflating: test/calls/calls_pod33.png  \n",
            "  inflating: test/calls/calls_pod344.png  \n",
            "  inflating: test/calls/calls_pod359.png  \n",
            "  inflating: test/calls/calls_pod348.png  \n",
            "  inflating: test/calls/calls_pod371.png  \n",
            "  inflating: test/calls/calls_pod328.png  \n",
            "  inflating: test/calls/calls_pod385.png  \n",
            "  inflating: test/calls/calls_pod333.png  \n",
            "  inflating: test/calls/calls_pod358.png  \n",
            "  inflating: test/calls/calls_pod341.png  \n",
            "  inflating: test/calls/calls_pod320.png  \n",
            "  inflating: test/calls/calls_pod310.png  \n",
            "  inflating: test/calls/calls_pod326.png  \n",
            "  inflating: test/calls/calls_pod355.png  \n",
            "  inflating: test/calls/calls_pod377.png  \n",
            "  inflating: test/calls/calls_pod361.png  \n",
            "  inflating: test/calls/calls_pod386.png  \n",
            "  inflating: test/calls/calls_pod325.png  \n",
            "  inflating: test/calls/calls_pod360.png  \n",
            "  inflating: test/calls/calls_pod35.png  \n",
            "  inflating: test/calls/calls_pod312.png  \n",
            "  inflating: test/calls/calls_pod353.png  \n",
            "  inflating: test/calls/calls_pod34.png  \n",
            "  inflating: test/calls/calls_pod321.png  \n",
            "  inflating: test/calls/calls_pod363.png  \n",
            "  inflating: test/calls/calls_pod384.png  \n",
            "  inflating: test/calls/calls_pod383.png  \n",
            "  inflating: test/calls/calls_pod324.png  \n",
            "  inflating: test/calls/calls_pod398.png  \n",
            "  inflating: test/calls/calls_pod39.png  \n",
            "  inflating: test/calls/calls_pod319.png  \n",
            "  inflating: test/calls/calls_pod354.png  \n",
            "  inflating: test/calls/calls_pod311.png  \n",
            "  inflating: test/calls/calls_pod376.png  \n",
            "  inflating: test/calls/calls_pod396.png  \n",
            "  inflating: test/calls/calls_pod378.png  \n",
            "  inflating: test/calls/calls_pod366.png  \n",
            "  inflating: test/calls/calls_pod372.png  \n",
            "  inflating: test/calls/calls_pod381.png  \n",
            "  inflating: test/calls/calls_pod322.png  \n",
            "  inflating: test/calls/calls_pod340.png  \n",
            "  inflating: test/calls/calls_pod357.png  \n",
            "  inflating: test/calls/calls_pod391.png  \n",
            "  inflating: test/calls/calls_pod350.png  \n",
            "  inflating: test/calls/calls_pod330.png  \n",
            "  inflating: test/calls/calls_pod374.png  \n",
            "  inflating: test/calls/calls_pod32.png  \n",
            "  inflating: test/calls/calls_pod36.png  \n",
            "  inflating: test/calls/calls_pod379.png  \n",
            "  inflating: test/calls/calls_pod334.png  \n",
            "  inflating: test/calls/calls_pod329.png  \n",
            "  inflating: test/calls/calls_pod364.png  \n",
            "  inflating: test/calls/calls_pod375.png  \n",
            "  inflating: test/calls/calls_pod349.png  \n",
            "  inflating: test/calls/calls_pod370.png  \n",
            "  inflating: test/calls/calls_pod3101.png  \n",
            "  inflating: test/calls/calls_pod392.png  \n",
            "  inflating: test/calls/calls_pod397.png  \n",
            "  inflating: test/calls/calls_pod347.png  \n",
            "  inflating: test/calls/calls_pod323.png  \n",
            "  inflating: test/calls/calls_pod356.png  \n",
            "  inflating: test/calls/calls_pod332.png  \n",
            "  inflating: test/calls/calls_pod367.png  \n",
            "  inflating: test/calls/calls_pod380.png  \n",
            "  inflating: test/calls/calls_pod316.png  \n",
            "  inflating: test/calls/calls_pod365.png  \n",
            "  inflating: test/calls/calls_pod339.png  \n",
            "  inflating: test/calls/calls_pod317.png  \n",
            "  inflating: test/calls/calls_pod394.png  \n",
            "  inflating: test/calls/calls_pod335.png  \n",
            "  inflating: test/calls/calls_pod331.png  \n",
            "  inflating: test/calls/calls_pod351.png  \n",
            "  inflating: test/calls/calls_pod373.png  \n",
            "  inflating: test/calls/calls_pod313.png  \n",
            "  inflating: test/calls/calls_pod37.png  \n",
            "  inflating: test/calls/calls_pod337.png  \n",
            "  inflating: test/calls/calls_pod395.png  \n",
            "  inflating: test/calls/calls_pod314.png  \n",
            "  inflating: test/calls/calls_pod31.png  \n",
            "  inflating: test/calls/calls_pod315.png  \n",
            "  inflating: test/calls/calls_pod3100.png  \n",
            "  inflating: test/calls/calls_pod387.png  \n",
            "  inflating: test/calls/calls_pod388.png  \n",
            "  inflating: test/calls/calls_pod389.png  \n",
            "  inflating: test/calls/calls_pod345.png  \n",
            "  inflating: test/calls/calls_pod382.png  \n",
            "  inflating: test/calls/calls_pod342.png  \n",
            "  inflating: test/calls/calls_pod343.png  \n",
            "  inflating: test/calls/calls_pod318.png  \n",
            "  inflating: test/calls/calls_pod336.png  \n",
            "  inflating: test/calls/calls_pod390.png  \n",
            "  inflating: test/calls/calls_pod368.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNGoAwdmoPpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "b21105e6-d4e1-4857-efd3-f8d18c92a634"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
        "predictions[predictions<=0.5] = 0\n",
        "predictions[predictions>0.5] = 1\n",
        "\n",
        "predicted_classes = (predictions).astype(np.int)\n",
        "\n",
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())   \n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 201 images belonging to 2 classes.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       calls       0.77      0.60      0.68       101\n",
            "     nocalls       0.67      0.82      0.74       100\n",
            "\n",
            "    accuracy                           0.71       201\n",
            "   macro avg       0.72      0.71      0.71       201\n",
            "weighted avg       0.72      0.71      0.71       201\n",
            "\n",
            "[[61 40]\n",
            " [18 82]]\n",
            "acc: 0.7114\n",
            "sensitivity: 0.6040\n",
            "specificity: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4YhRKkofh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "f5a17a3c-2c99-4cbc-80d2-3ad3790ac85e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
        "predictions[predictions<=0.5] = 0\n",
        "predictions[predictions>0.5] = 1\n",
        "\n",
        "predicted_classes = (predictions).astype(np.int)\n",
        "\n",
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())   \n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 201 images belonging to 2 classes.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       calls       0.86      0.60      0.71       101\n",
            "     nocalls       0.69      0.90      0.78       100\n",
            "\n",
            "    accuracy                           0.75       201\n",
            "   macro avg       0.78      0.75      0.75       201\n",
            "weighted avg       0.78      0.75      0.75       201\n",
            "\n",
            "[[61 40]\n",
            " [10 90]]\n",
            "acc: 0.7512\n",
            "sensitivity: 0.6040\n",
            "specificity: 0.9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dANzj_Syimx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "68aec847-bee1-4a74-89b0-f7674ab500e0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
        "predictions[predictions<=0.5] = 0\n",
        "predictions[predictions>0.5] = 1\n",
        "\n",
        "predicted_classes = (predictions).astype(np.int)\n",
        "\n",
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())   \n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 201 images belonging to 2 classes.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       calls       0.84      0.68      0.75       101\n",
            "     nocalls       0.73      0.87      0.79       100\n",
            "\n",
            "    accuracy                           0.78       201\n",
            "   macro avg       0.79      0.78      0.77       201\n",
            "weighted avg       0.79      0.78      0.77       201\n",
            "\n",
            "[[69 32]\n",
            " [13 87]]\n",
            "acc: 0.7761\n",
            "sensitivity: 0.6832\n",
            "specificity: 0.8700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg4uvPY71tYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "e3f9565e-8632-4ffe-ecb0-97ca2109e06a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
        "predictions[predictions<=0.5] = 0\n",
        "predictions[predictions>0.5] = 1\n",
        "\n",
        "predicted_classes = (predictions).astype(np.int)\n",
        "\n",
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())   \n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 201 images belonging to 2 classes.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       calls       0.84      0.72      0.78       101\n",
            "     nocalls       0.75      0.86      0.80       100\n",
            "\n",
            "    accuracy                           0.79       201\n",
            "   macro avg       0.80      0.79      0.79       201\n",
            "weighted avg       0.80      0.79      0.79       201\n",
            "\n",
            "[[73 28]\n",
            " [14 86]]\n",
            "acc: 0.7910\n",
            "sensitivity: 0.7228\n",
            "specificity: 0.8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPMRf9Ps7M-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}